{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mashurin_595_task8.ipynb",
      "version": "0.3.2",
      "views": {},
      "default_view": {},
      "provenance": [
        {
          "file_id": "1Xtn4UTJOeQ999g78urAnPaZgboio8dz5",
          "timestamp": 1524199403566
        }
      ],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "t8PaG2TzbmtG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Organization Info</h1> \n",
        "\n",
        "* Дедлайн **DD MM 2018 23:59** для всех групп.\n",
        "* В качестве решения задания нужно прислать ноутбук с подробными комментариями (<span style='color:red'> без присланного решения результат контеста не будет засчитан </span>).\n",
        "* <span style='color:red'>Название команды в контесте должно соответствовать шаблону: НомерГруппы_Имя_Фамилия, например, 594_Ivan_Ivanov</span>."
      ]
    },
    {
      "metadata": {
        "id": "09hIEL2ubmtI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**Оформление дз**: \n",
        "- Присылайте выполненное задание на почту ``ml.course.mipt@gmail.com``\n",
        "- Укажите тему письма в следующем формате ``ML2018_fall_<номер_группы>_<фамилия>``, к примеру -- ``ML2018_fall_495_ivanov``\n",
        "- Выполненное дз сохраните в файл ``<фамилия>_<группа>_task<номер>.ipnb, к примеру`` -- ``ivanov_401_task7.ipnb``\n",
        "\n",
        "**Вопросы**:\n",
        "- Присылайте вопросы на почту ``ml.course.mipt@gmail.com``\n",
        "- Укажите тему письма в следующем формате ``ML2018_fall Question <Содержание вопроса>``\n",
        "\n",
        "\n",
        "--------\n",
        "- **PS1:** Используются автоматические фильтры, и просто не найдем ваше дз, если вы неаккуратно его подпишите.\n",
        "- **PS2:**  Просроченный дедлайн снижает максимальный вес задания по формуле, указнной на первом семинаре\n",
        "- **PS3:** Допустимы исправление кода предложенного кода ниже, если вы считаете"
      ]
    },
    {
      "metadata": {
        "id": "H_TKuSMqbmtI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<h1 align=\"center\">Checking Questions</h1> \n",
        "\n",
        "**Вопрос 1**: Чем LSTM лучше/хуже чем обычная RNN?\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "Лучше: RNN имеет проблемы с градиентами (они могут затухать или наоборот взрывается), в отличии от LSTM, где это проблема решена с помощью forget gate. Это на самом деле, очень крутая фича.\n",
        "\n",
        "Хуже: Главный минум относительно RNN - медленнее учится, а также сложнее (что плохо для понимания).\n",
        "\n",
        "**Вопрос 2**:  Выпишите производную $\\frac{d c_{n+1}}{d c_{k}}$ для LSTM http://colah.github.io/posts/2015-08-Understanding-LSTMs/, объясните формулу, когда производная затухает, когда взрывается?\n",
        "\n",
        "**Ответ:**\n",
        "\n",
        "**Вопрос 3**: Зачем нужен TBPTT почему BPTT плох?\n",
        "\n",
        "**Ответ:** Проблема BPTT в градиентах (они могут взрываться). TBPTT решает эту проблему, для этого он и нужен.\n",
        "\n",
        "**Вопрос 4**: Как комбинировать рекуррентные и сверточные сети, а главное зачем? Приведите несколько примеров реальных задач.\n",
        "\n",
        "**Ответ:** Используются, например, в задаче генерации подписи к изображениям. Как комбинировать рекуррентные и сверточные сети: выход сверточной сети можно сувать на разные итерации рекуррентной. Зачем: когда мы хотим сувать не голые изображения, а какую-нибудь хорошую сеть.\n",
        "\n",
        "**Вопрос 5**: Можно ли использовать сверточные сети для классификации текстов? Если нет обоснуйте :D, если да то как? как решить проблему с произвольной длинной входа?\n",
        "\n",
        "**Ответ:** Нужно рассмотреть word embedding и работать с ними как с пикселями у изображений.\n",
        "\n",
        "**Вопрос 6**: Attention - что это такое, где применяют и как? Приведите пример использования на какой-нибудь задаче\n",
        "\n",
        "**Ответ:** Attention - это так называемый механизм внимания. Большинство NMT-систем работают, кодируя исходное предложение в вектор, используя повторяющуюся нейронную сеть, а затем декодируют предложение на основе этого вектора, также используя RNN. С механизмом внимания мы больше не пытаемся кодировать полное предложение источника в вектор фиксированной длины. Скорее, мы разрешаем декодеру «посещать» разные части исходного предложения на каждом этапе генерации вывода.\n",
        "\n",
        "Пример использования в задача, которую мы решали ниже (в Part1 и Part2)."
      ]
    },
    {
      "metadata": {
        "id": "SwvcbIfrbmtJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Grading\n",
        "* starting at zero points\n",
        "* +2 for describing your iteration path in a report below (compare models).\n",
        "* +2 for correct check questions\n",
        "* +3 (7 total) for 99% accuracy with simple NMT model on __TEST__ dataset\n",
        "* +3 (10 total) for 99% accuracy with attention NMT model on __TEST__ dataset\n",
        "----\n",
        "* tatoeba bonus for accuracy on __TEST__ dataset:\n",
        "    * +2 for report\n",
        "    * 60% (14 total)\n",
        "    * 65% (16 total)\n",
        "    * 70% (18 total)\n",
        "    * 75% (20 total)\n",
        "    \n",
        "## Bonus points\n",
        "\n",
        "Common ways to get bonus points are:\n",
        "* Get higher score, obviously.\n",
        "* Anything special about your NN. For example \"A super-small/fast NN that gets 99%\" gets a bonus.\n",
        "* Any detailed analysis of the results. (attention maps, whatever)"
      ]
    },
    {
      "metadata": {
        "id": "TmV6rbFnbmtK",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "tgmx5FmMbmtL",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# additional packages for this notebook"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PBt3T39ybmtO",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "080397db-6216-4199-a006-4e378fbbb7a0",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525803915095,
          "user_tz": -180,
          "elapsed": 2525,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! pip install faker tqdm babel"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: faker in /usr/local/lib/python3.6/dist-packages (0.8.13)\r\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (4.23.3)\n",
            "Requirement already satisfied: babel in /usr/local/lib/python3.6/dist-packages (2.5.3)\n",
            "Requirement already satisfied: text-unidecode==1.2 in /usr/local/lib/python3.6/dist-packages (from faker) (1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.6/dist-packages (from faker) (2.5.3)\n",
            "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.6/dist-packages (from faker) (1.11.0)\n",
            "Requirement already satisfied: pytz>=0a in /usr/local/lib/python3.6/dist-packages (from babel) (2018.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "a-ZgiRZ0bmtR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task - translation\n",
        "\n",
        "The machine translation is old and well-known field in natural language processing. From the 1950s scientists tried to create a model to automatically translate from say French to English. Nowadays it became possible and the attention mechanism takes great part in that. Here the example image with attention map for the neural machine translation of sample phrase:\n",
        "<p align=\"center\">\n",
        "  <img src=\"http://d3kbpzbmcynnmx.cloudfront.net/wp-content/uploads/2015/12/Screen-Shot-2015-12-30-at-1.23.48-PM.png\" width=\"400\">\n",
        "</p>"
      ]
    },
    {
      "metadata": {
        "id": "_G0I7FPrbmtR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "In our lab we will concentrate on much simplier task: we will translate from human readable date to machine readable one.\n",
        "\n",
        "To do this we need to get one more concept - Sequence-to-Sequence language modeling.\n",
        "The idea of such architecture is here:\n",
        "<p aling=\"center\">\n",
        "<img src=\"./img/simple_nmt.jpg\" width=\"400\">\n",
        "</p>\n",
        "\n",
        "There is an Embeding layer at the bottom, the RNN in the middle and softmax as an output."
      ]
    },
    {
      "metadata": {
        "id": "z9tGNB0m5bq3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from keras.layers import Embedding, Bidirectional\n",
        "from keras.layers.core import *\n",
        "from keras.layers.recurrent import LSTM\n",
        "from keras.models import *\n",
        "from keras.layers.merge import Multiply\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import TimeDistributed\n",
        "\n",
        "import keras.backend as K\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0T061-w5bmtY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "KmeoyFFkbmtZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "DiHiJe835brn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Now we need to generate data. It will be dates in different text formats and in fixed output format."
      ]
    },
    {
      "metadata": {
        "id": "Lqr3mM4D5bro",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "from babel.dates import format_date\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pi8idIsn5brw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fake = Faker()\n",
        "\n",
        "FORMATS = ['short',\n",
        "           'medium',\n",
        "           'long',\n",
        "           'full',\n",
        "           'd MMM YYY', \n",
        "           'd MMMM YYY',\n",
        "           'dd MMM YYY',\n",
        "           'd MMM, YYY',\n",
        "           'd MMMM, YYY',\n",
        "           'dd, MMM YYY',\n",
        "           'd MM YY',\n",
        "           'd MMMM YYY',\n",
        "           'MMMM d YYY',\n",
        "           'MMMM d, YYY',\n",
        "           'dd.MM.YY']\n",
        "\n",
        "# change this if you want it to work with another language\n",
        "LOCALES = ['en_US']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "67qzEjMm5br1",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_date():\n",
        "    \"\"\"\n",
        "        Creates some fake dates \n",
        "        :returns: tuple containing human readable string, machine readable string, and date object\n",
        "    \"\"\"\n",
        "    dt = fake.date_object()\n",
        "\n",
        "    try:\n",
        "        human_readable = format_date(dt, format=random.choice(FORMATS), locale=random.choice(LOCALES))\n",
        "\n",
        "        case_change = random.choice([0,1,2])\n",
        "        if case_change == 1:\n",
        "            human_readable = human_readable.upper()\n",
        "        elif case_change == 2:\n",
        "            human_readable = human_readable.lower()\n",
        "        # if case_change == 0, do nothing\n",
        "\n",
        "        machine_readable = dt.isoformat()\n",
        "    except AttributeError as e:\n",
        "        return None, None, None\n",
        "\n",
        "    return human_readable, machine_readable, dt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j9eTZ13P5br6",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def create_dataset(n_examples):\n",
        "    \"\"\"\n",
        "        Creates a dataset with n_examples and vocabularies\n",
        "        :n_examples: the number of examples to generate\n",
        "    \"\"\"\n",
        "    human_vocab = set()\n",
        "    machine_vocab = set()\n",
        "    dataset = []\n",
        "\n",
        "    for i in tqdm(range(n_examples)):\n",
        "        h, m, _ = create_date()\n",
        "        if h is not None:\n",
        "            dataset.append((h, m))\n",
        "            human_vocab.update(tuple(h))\n",
        "            machine_vocab.update(tuple(m))\n",
        "\n",
        "    human = dict(zip(list(human_vocab) + ['<unk>', '<pad>'], \n",
        "                     list(range(len(human_vocab) + 2))))\n",
        "    inv_machine = dict(enumerate(list(machine_vocab) + ['<unk>', '<pad>']))\n",
        "    machine = {v:k for k,v in inv_machine.items()}\n",
        " \n",
        "    return dataset, human, machine, inv_machine"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EsQHOc3D5br9",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def string_to_int(string, lenght, vocab):\n",
        "    if len(string) > lenght:\n",
        "        string = string[:lenght]\n",
        "        \n",
        "    rep = list(map(lambda x: vocab.get(x, '<unk>'), string))\n",
        "    \n",
        "    if len(string) < lenght:\n",
        "        rep += [vocab['<pad>']] * (lenght - len(string))\n",
        "    \n",
        "    return rep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MYU62jZi5bsB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def int_to_string(ints, inv_vocab):\n",
        "    return [inv_vocab[i] for i in ints]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yTghggDB5bsE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actually generating data:"
      ]
    },
    {
      "metadata": {
        "id": "As0XeIDa5bsF",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "89c383a7-6c5c-4877-8919-c078bde9201b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525803944487,
          "user_tz": -180,
          "elapsed": 19072,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "fake.seed(42)\n",
        "random.seed(42)\n",
        "N = int(3e5)\n",
        "dataset, human_vocab, machine_vocab, inv_machine_vocab = create_dataset(N)"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 300000/300000 [00:18<00:00, 16292.35it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "qwN8hGFn23Pt",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b6ec2388-20a0-4aec-a78c-9f477ef5017c",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525803945094,
          "user_tz": -180,
          "elapsed": 574,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "dataset[2]"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tuesday, september 14, 1971', '1971-09-14')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "metadata": {
        "id": "7KkWLPc8cbBU",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 20"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ITej2gDY5bsN",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs, targets = zip(*dataset)\n",
        "inputs = np.array([string_to_int(i, TIME_STEPS, human_vocab) for i in inputs])\n",
        "targets = [string_to_int(t, TIME_STEPS, machine_vocab) for t in targets]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(machine_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4H1wx5Dsbmty",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "X_train, y_train, X_valid, y_valid, X_test, y_test = (\n",
        "    inputs[:int(2e5)], targets[:int(2e5)], \n",
        "    inputs[int(2e5):-int(5e4)], targets[int(2e5):-int(5e4)],  \n",
        "    inputs[-int(5e4):], targets[-int(5e4):], )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SYqFzRuoOsWu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ea0ebe8d-54ad-4c89-8219-5e4f7a44e509",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525803956391,
          "user_tz": -180,
          "elapsed": 492,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "print(X_train.shape, y_train.shape)\n",
        "print(len(human_vocab), len(machine_vocab))"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(200000, 20) (200000, 20, 13)\n",
            "60 13\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HQItG5gUbmt1",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "N1eOIJ31bmt2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 1: Simple NMT"
      ]
    },
    {
      "metadata": {
        "id": "ppldfWWEqFoX",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qWo4x0DM5brd",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# :good-enouht:\n",
        "ENCODER_UNITS = 64 # change me if u want\n",
        "DECODER_UNITS = 32 # change me if u want\n",
        "TIME_STEPS = 20 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "QQD_Dy8_0MSx",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# input - [bs; in_time_len]\n",
        "# output - [bs; out_time_len]; out_time_len=10\n",
        "\n",
        "def model_simple_nmt(in_chars, out_chars):\n",
        "    # RNN encoder -> hidden representation -> RNN decoder\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    embedding = Embedding(input_dim=in_chars, output_dim=ENCODER_UNITS, input_length=TIME_STEPS)(inputs)\n",
        "    lstm = Bidirectional(LSTM(DECODER_UNITS, return_sequences=True))(embedding)\n",
        "    dense = Dense(out_chars, activation='softmax')(lstm)\n",
        "    \n",
        "    model = Model(input=[inputs], output=dense)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztwvgRe35bsJ",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "f782045a-72cd-492a-da3b-a213990abaee",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525793370184,
          "user_tz": -180,
          "elapsed": 1458,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 20)                0         \n",
            "_________________________________________________________________\n",
            "embedding_1 (Embedding)      (None, 20, 64)            3840      \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 20, 64)            24832     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 20, 13)            845       \n",
            "=================================================================\n",
            "Total params: 29,517\n",
            "Trainable params: 29,517\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:9: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=Tensor(\"de...)`\n",
            "  if __name__ == '__main__':\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "l_wPSU2t5bsP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "daab5f63-4d2c-4f38-ec49-64e7b6d3ebb7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525798084606,
          "user_tz": -180,
          "elapsed": 2384899,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [X_train], y_train, \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=7, batch_size=64, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/7\n",
            " 42240/200000 [=====>........................] - ETA: 4:15 - loss: 0.0431 - acc: 0.9864\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "113152/200000 [===============>..............] - ETA: 2:19 - loss: 0.0374 - acc: 0.9877"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "184960/200000 [==========================>...] - ETA: 24s - loss: 0.0351 - acc: 0.9883"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 341s 2ms/step - loss: 0.0347 - acc: 0.9885 - val_loss: 0.0374 - val_acc: 0.9873\n",
            "Epoch 2/7\n",
            " 21440/200000 [==>...........................] - ETA: 4:45 - loss: 0.0306 - acc: 0.9896"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 93376/200000 [=============>................] - ETA: 2:51 - loss: 0.0299 - acc: 0.9897"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "170496/200000 [========================>.....] - ETA: 47s - loss: 0.0301 - acc: 0.9897"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 341s 2ms/step - loss: 0.0295 - acc: 0.9899 - val_loss: 0.0265 - val_acc: 0.9908\n",
            "Epoch 3/7\n",
            " 15872/200000 [=>............................] - ETA: 4:59 - loss: 0.0275 - acc: 0.9903"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 87104/200000 [============>.................] - ETA: 3:01 - loss: 0.0258 - acc: 0.9909"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "157568/200000 [======================>.......] - ETA: 1:07 - loss: 0.0292 - acc: 0.9900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 340s 2ms/step - loss: 0.0281 - acc: 0.9903 - val_loss: 0.0236 - val_acc: 0.9913\n",
            "Epoch 4/7\n",
            " 10624/200000 [>.............................] - ETA: 5:04 - loss: 0.0241 - acc: 0.9911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81088/200000 [===========>..................] - ETA: 3:09 - loss: 0.0239 - acc: 0.9912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "154560/200000 [======================>.......] - ETA: 1:12 - loss: 0.0240 - acc: 0.9913"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 339s 2ms/step - loss: 0.0238 - acc: 0.9913 - val_loss: 0.0224 - val_acc: 0.9918\n",
            "Epoch 5/7\n",
            "  9664/200000 [>.............................] - ETA: 5:07 - loss: 0.0217 - acc: 0.9920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81664/200000 [===========>..................] - ETA: 3:09 - loss: 0.0270 - acc: 0.9906"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "152192/200000 [=====================>........] - ETA: 1:16 - loss: 0.0246 - acc: 0.9911"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 340s 2ms/step - loss: 0.0238 - acc: 0.9913 - val_loss: 0.0217 - val_acc: 0.9918\n",
            "Epoch 6/7\n",
            "  9088/200000 [>.............................] - ETA: 5:02 - loss: 0.0222 - acc: 0.9914"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 79936/200000 [==========>...................] - ETA: 3:10 - loss: 0.0219 - acc: 0.9916"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "150656/200000 [=====================>........] - ETA: 1:18 - loss: 0.0240 - acc: 0.9912"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 340s 2ms/step - loss: 0.0231 - acc: 0.9915 - val_loss: 0.0203 - val_acc: 0.9922\n",
            "Epoch 7/7\n",
            "  8768/200000 [>.............................] - ETA: 5:11 - loss: 0.0202 - acc: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 81408/200000 [===========>..................] - ETA: 3:11 - loss: 0.0206 - acc: 0.9920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "164224/200000 [=======================>......] - ETA: 57s - loss: 0.0208 - acc: 0.9920"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 343s 2ms/step - loss: 0.0213 - acc: 0.9918 - val_loss: 0.0214 - val_acc: 0.9918\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f1d3c7940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "metadata": {
        "id": "hz5Q76iDbmuG",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "45fddf95-b2d5-41b4-e305-f400ee29cc4f",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525798129620,
          "user_tz": -180,
          "elapsed": 44906,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 44s 889us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.021406254270747303, 0.9917460008621216]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "metadata": {
        "id": "fwYByTjJ5bsS",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Lets check our model:"
      ]
    },
    {
      "metadata": {
        "id": "EIMBnjqY5bsS",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "EXAMPLES = ['3 May 1979', '5 Apr 09', '20th February 2016', 'Wed 10 Jul 2007']\n",
        "\n",
        "def run_example(model, input_vocabulary, inv_output_vocabulary, text):\n",
        "    encoded = string_to_int(text, TIME_STEPS, input_vocabulary)\n",
        "    prediction = model.predict(np.array([encoded]))\n",
        "    prediction = np.argmax(prediction[0], axis=-1)\n",
        "    return int_to_string(prediction, inv_output_vocabulary)\n",
        "\n",
        "def run_examples(model, input_vocabulary, inv_output_vocabulary, examples=EXAMPLES):\n",
        "    predicted = []\n",
        "    for example in examples:\n",
        "        predicted.append(''.join(run_example(model, input_vocabulary, inv_output_vocabulary, example)))\n",
        "        print('input:', example)\n",
        "        print('output:', predicted[-1])\n",
        "    return predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0cSByOaY5bsW",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "1b7edcbb-7c57-4d94-c886-5ca14df76e10",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525798130888,
          "user_tz": -180,
          "elapsed": 508,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_examples(m, human_vocab, inv_machine_vocab)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "input: 3 May 1979\n",
            "output: 1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 5 Apr 09\n",
            "output: 2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: 20th February 2016\n",
            "output: 2012-06-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n",
            "input: Wed 10 Jul 2007\n",
            "output: 2007-06-00<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['1979-05-03<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2009-04-05<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2012-06-20<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>',\n",
              " '2007-06-00<pad><pad><pad><pad><pad><pad><pad><pad><pad><pad>']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "metadata": {
        "id": "9dxpHKlg5bsy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "outputId": "d00d82dd-83c0-4e90-e3ae-958a2f33a48d",
        "executionInfo": {
          "status": "error",
          "timestamp": 1525798131569,
          "user_tz": -180,
          "elapsed": 477,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "---"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-54-29e0c3615294>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    ---\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "0V-pkNX4bmuP",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Part 2: All u need is attention"
      ]
    },
    {
      "metadata": {
        "id": "-zDW4e6j5brg",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Here we use more complex idea that simple seq2seq: we're adding two explicit parts of our network - encoder and decoder (which is applied attention on). The explanatory picture for this idea is below:\n",
        "<p aling=\"center\"><img src=\"https://i.stack.imgur.com/Zwsmz.png\"></p>\n",
        "\n",
        "The lower part of the network is encoding the input to some hidden intermediate representation and the upper part is decoing the hidвen represenataion into some readable output."
      ]
    },
    {
      "metadata": {
        "id": "cbXUw3L5bmuP",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# :good-enouht:\n",
        "ENCODER_UNITS = 32 # change me if u want\n",
        "DECODER_UNITS = 32 # change me if u want\n",
        "TIME_STEPS = 20 # change me if u want"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Iarsrwwy0xBB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_simple_nmt(in_chars, out_chars):\n",
        "    encoder_input = Input(shape=(TIME_STEPS,))\n",
        "    encoder_embedding = Embedding(input_dim=in_chars, output_dim=ENCODER_UNITS, input_length=TIME_STEPS)(encoder_input)\n",
        "    encoder_LSTM = LSTM(ENCODER_UNITS,return_state = True)\n",
        "    encoder_outputs, encoder_h, encoder_c = encoder_LSTM(encoder_embedding)\n",
        "    encoder_states = [encoder_h, encoder_c]\n",
        "    #Attention\n",
        "    dense = Dense(20, activation='softmax')(encoder_outputs)\n",
        "    rv = RepeatVector(20)(dense)\n",
        "    \n",
        "    decoder_LSTM = LSTM(DECODER_UNITS,return_sequences=True, return_state = True)\n",
        "    decoder_out, _ , _ = decoder_LSTM(rv, initial_state=encoder_states)\n",
        "    decoder_dense = Dense(out_chars, activation='softmax')\n",
        "    decoder_out = decoder_dense(decoder_out)\n",
        "    model = Model(inputs=[encoder_input],outputs=decoder_out)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Lmg9Nqe4aEpv",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "caa20f06-ff23-459c-d048-8546270c97a7",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525804440316,
          "user_tz": -180,
          "elapsed": 1147,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_simple_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_27 (InputLayer)           (None, 20)           0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding_18 (Embedding)        (None, 20, 32)       1920        input_27[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_28 (LSTM)                  [(None, 32), (None,  8320        embedding_18[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 20)           660         lstm_28[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector_3 (RepeatVector)  (None, 20, 20)       0           dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "lstm_29 (LSTM)                  [(None, 20, 32), (No 6784        repeat_vector_3[0][0]            \n",
            "                                                                 lstm_28[0][1]                    \n",
            "                                                                 lstm_28[0][2]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 20, 13)       429         lstm_29[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 18,113\n",
            "Trainable params: 18,113\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "uXPTfSIQaIIC",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "ea774b58-0b36-4a56-de63-c5cc59a2cd9b",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525806145925,
          "user_tz": -180,
          "elapsed": 1701435,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [X_train], y_train, \n",
        "    validation_data=(X_valid, y_valid),\n",
        "    epochs=5, batch_size=64, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 200000 samples, validate on 50000 samples\n",
            "Epoch 1/5\n",
            " 41600/200000 [=====>........................] - ETA: 4:18 - loss: 0.9305 - acc: 0.7037"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "112768/200000 [===============>..............] - ETA: 2:20 - loss: 0.6360 - acc: 0.7829"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "183872/200000 [==========================>...] - ETA: 25s - loss: 0.4933 - acc: 0.8320"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 339s 2ms/step - loss: 0.4695 - acc: 0.8402 - val_loss: 0.1878 - val_acc: 0.9376\n",
            "Epoch 2/5\n",
            " 21440/200000 [==>...........................] - ETA: 4:45 - loss: 0.1740 - acc: 0.9433"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 92352/200000 [============>.................] - ETA: 2:51 - loss: 0.1434 - acc: 0.9531"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "163456/200000 [=======================>......] - ETA: 58s - loss: 0.1228 - acc: 0.9602"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 338s 2ms/step - loss: 0.1142 - acc: 0.9633 - val_loss: 0.0744 - val_acc: 0.9764\n",
            "Epoch 3/5\n",
            " 12928/200000 [>.............................] - ETA: 4:59 - loss: 0.0686 - acc: 0.9801"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 84928/200000 [===========>..................] - ETA: 3:04 - loss: 0.0579 - acc: 0.9837"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "154816/200000 [======================>.......] - ETA: 1:12 - loss: 0.0509 - acc: 0.9855"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 337s 2ms/step - loss: 0.0474 - acc: 0.9864 - val_loss: 0.0338 - val_acc: 0.9894\n",
            "Epoch 4/5\n",
            "  9472/200000 [>.............................] - ETA: 5:03 - loss: 0.0326 - acc: 0.9900"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 82304/200000 [===========>..................] - ETA: 3:08 - loss: 0.0307 - acc: 0.9902"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "156480/200000 [======================>.......] - ETA: 1:09 - loss: 0.0284 - acc: 0.9908"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 341s 2ms/step - loss: 0.0274 - acc: 0.9910 - val_loss: 0.0222 - val_acc: 0.9921\n",
            "Epoch 5/5\n",
            " 10560/200000 [>.............................] - ETA: 5:04 - loss: 0.0234 - acc: 0.9918"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            " 80960/200000 [===========>..................] - ETA: 3:10 - loss: 0.0220 - acc: 0.9921"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "154560/200000 [======================>.......] - ETA: 1:13 - loss: 0.0214 - acc: 0.9922"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "200000/200000 [==============================] - 343s 2ms/step - loss: 0.0209 - acc: 0.9923 - val_loss: 0.0184 - val_acc: 0.9928\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f7f1759f9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "metadata": {
        "id": "bFZE8QS4bmub",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          },
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "5ba6a92c-0de9-4bfb-9554-8799c97505d8",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1525806190973,
          "user_tz": -180,
          "elapsed": 45027,
          "user": {
            "displayName": "Влад Машурин",
            "photoUrl": "https://lh3.googleusercontent.com/a/default-user=s128",
            "userId": "115582581376242788795"
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.evaluate([X_test], y_test)"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50000/50000 [==============================] - 44s 886us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01843271078594029, 0.9928049998092652]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "metadata": {
        "id": "LgvBw6WiZXBy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "---"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "z6ZFnOY2bmud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Report\n",
        "\n",
        "* final architectures:\n",
        "\n",
        "Part 1: input + embedding + bidirectional(LSTM) + dense\n",
        "\n",
        "Part 2: input + embedding + LSTM + dense + repeat_vector + LSTM + dense\n",
        "\n",
        "* comparison\n",
        "\n",
        "Как и планировалось, скор у Part 2 (с attention) получился выше, даже учитывая, что у Part 1 было 12 эпох в сумме, а у Part 2 было 5 эпох. Лосс у Part 2, как мы видим, тоже получился меньше, чем у Part 1. Можно сделать вывод, что attention со своей функцией справляется.\n",
        "\n",
        "* as well as training method and tricks\n",
        "\n",
        "Как я получал модель Part 1: для начала я прочитал лекции и семинары, а также изучил статью https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html Part 1 описан в статье, как базовый случай и сразу стало понятно, что для его реализации нам понадобится LSTM, а также Dense. После изучания LSTM стало понятно, что нужна \"кодировка\" в лице embedding. Я добавил embedding. Запустил. Училось хорошо, но недостаточно быстро и на 10 эпохах только доходило до 0.9. Нужно было как-то увеличивать скор. После прочтения многих гайдов и статей я понял, что требуется добавить bidirectional. Он должен был помощь. И он помог. Для начала я запустил на 5 этохах. Скор был 0.98, после, я добавил еще 7 эпох (как позже оказалось, хватило бы в общей сложности 8 эпох) и модель доучилась до 0.99+.\n",
        "\n",
        "Как я получал модель Part 2: Как известно из предыдущего абзаца, я прочитал статью. Из нее становится понятно, что базовый случай не прокатит и нужно делать общий. Я реализовал input + embedding + LSTM + dense и стал думать над \"своим\" attention. Прочитав еще раз лекцию, я понял, что нам нужно добавить слои dense(softmax) + repeat_vector. Это действительно будет похоже на обычный attention, так как мы будем фокусироваться на отдельных вещах, правда, будет делать это всего 1 раз (поэтому ожидать сильного буста не стоит), но в итоге небольшой буст мы получили. Так я получил итоговыю модель.\n",
        " "
      ]
    },
    {
      "metadata": {
        "id": "T1_2qEZsbmud",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "---"
      ]
    },
    {
      "metadata": {
        "id": "hGqjLqitbmue",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Part 3*: tatoeba - real NMT"
      ]
    },
    {
      "metadata": {
        "id": "8R4Z94Lhbmuf",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Data"
      ]
    },
    {
      "metadata": {
        "id": "hWRpJqWDbmuf",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "# dataset from http://www.manythings.org/anki/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZo-vZoZbmuh",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! wget http://www.manythings.org/anki/rus-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jLiTM_cgbmuk",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "! unzip ./rus-eng.zip"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FPbVNWiwbmun",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "with open(\"./rus.txt\") as fin:\n",
        "    data = fin.readlines()\n",
        "data = list(map(lambda x: x.replace(\"\\n\", \"\").lower(), data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_y6VzOBNbmup",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kAT6Ate8bmur",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data = data[:int(1e5)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sDUVFU5Xbmuu",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "sI6xAoj7bmuw",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "data[-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZZF9O74obmuy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "----"
      ]
    },
    {
      "metadata": {
        "id": "ie55q9Ldbmuy",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source = list(map(lambda x: x.split(\"\\t\")[0], data))\n",
        "target = list(map(lambda x: x.split(\"\\t\")[1], data))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1qaBw0JDbmu2",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab = set(\"\".join(source).strip())\n",
        "target_vocab = set(\"\".join(target).strip())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1utXtVdKbmu3",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "source_vocab = dict(zip(\n",
        "    list(source_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(source_vocab) + 2))))\n",
        "target_vocab = dict(zip(\n",
        "    list(target_vocab) + ['<unk>', '<pad>'], \n",
        "    list(range(len(target_vocab) + 2))))\n",
        "inv_target_vocab = dict(enumerate(list(target_vocab) + ['<unk>', '<pad>']))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZmJ5zTtbmu8",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "TIME_STEPS = 32\n",
        "ENCODER_UNITS = 256\n",
        "DECODER_UNITS = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5PzkK6q1bmu-",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "def model_simple_nmt_tatoeba(in_chars, out_chars):\n",
        "    inputs = Input(shape=(TIME_STEPS,))\n",
        "    \n",
        "    # your code\n",
        "\n",
        "    model = Model(input=[inputs], output=output)\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e804IXrTbmvA",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m = model_attention_nmt(len(human_vocab), len(machine_vocab))\n",
        "\n",
        "m.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "print(m.summary())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jMqj4Ku-bmvB",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "inputs = np.array([string_to_int(i, TIME_STEPS, source_vocab) for i in source])\n",
        "targets = [string_to_int(t, TIME_STEPS, target_vocab) for t in target]\n",
        "targets = np.array(list(map(lambda x: to_categorical(x, num_classes=len(target_vocab)), targets)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vka6zONibmvD",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "m.fit(\n",
        "    [inputs], targets, \n",
        "    epochs=10, batch_size=64, \n",
        "    validation_split=0.1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KnJuOmg4bmvE",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        "run_example(m, source_vocab, inv_target_vocab, 'hello')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0as0ut6ObmvG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Tatoeba Report\n",
        "\n",
        "* final architectures\n",
        "* comparison\n",
        "* as well as training method and tricks\n"
      ]
    },
    {
      "metadata": {
        "id": "3aNAOcTHbmvH",
        "colab_type": "code",
        "colab": {
          "autoexec": {
            "startup": false,
            "wait_interval": 0
          }
        }
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}